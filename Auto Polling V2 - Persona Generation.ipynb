{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e20385",
   "metadata": {},
   "source": [
    "# Auto Polling\n",
    "    - The original persona generation worked, but the personas were too generic and didnt give a model context to \n",
    "        make accurate predictions of the beliefs of a person\n",
    "    - Now making a new pipeline that will create personas in different stages to \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f276369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utils.Chat_GPT_Funcs as GPT\n",
    "import concurrent.futures\n",
    "import os\n",
    "import json\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346d525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_if_not_exists(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5973b7",
   "metadata": {},
   "source": [
    "# Load First and Last Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f34d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eths = [\"White\", \"American Indian or Alaska Native\", \"Black or African American\", \"Asian\", \"Hispanic or Latino\"]\n",
    "genders = ['Men', 'Women']\n",
    "\n",
    "dems = []\n",
    "for e in eths:\n",
    "    for g in genders:\n",
    "        s = f\"{e} {g}\"\n",
    "        dems.append(s)\n",
    "        \n",
    "first_names = {}\n",
    "for d in dems:\n",
    "    # Open the file in read binary mode\n",
    "    with open(f\"Names/First_Names/{d}.pkl\", \"rb\") as file:\n",
    "        # Use pickle to load the list object from the file\n",
    "        my_list = pickle.load(file)\n",
    "        first_names[d] = my_list\n",
    "\n",
    "last_names = {}\n",
    "for e in eths:\n",
    "    # Open the file in read binary mode\n",
    "    with open(f\"Names/Last_Names/{e}.pkl\", \"rb\") as file:\n",
    "        # Use pickle to load the list object from the file\n",
    "        my_list = pickle.load(file)\n",
    "        last_names[e] = my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485dfe07",
   "metadata": {},
   "source": [
    "# Top 44 Universities in USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ffe0406",
   "metadata": {},
   "outputs": [],
   "source": [
    "universities = [\n",
    "    \"Massachusetts Institute of Technology (MIT)\",\n",
    "    \"Stanford University\",\n",
    "    \"Harvard University\",\n",
    "    \"California Institute of Technology (Caltech)\",\n",
    "    \"University of Chicago\",\n",
    "    \"University of Pennsylvania\",\n",
    "    \"Princeton University\",\n",
    "    \"Yale University\",\n",
    "    \"Cornell University\",\n",
    "    \"Columbia University\",\n",
    "    \"Johns Hopkins University\",\n",
    "    \"University of Michigan-Ann Arbor\",\n",
    "    \"University of California Berkeley (UCB)\",\n",
    "    \"Northwestern University\",\n",
    "    \"New York University (NYU)\",\n",
    "    \"University of California, Los Angeles (UCLA)\",\n",
    "    \"Duke University\",\n",
    "    \"Carnegie Mellon University\",\n",
    "    \"University of California, San Diego (UCSD)\",\n",
    "    \"Brown University\",\n",
    "    \"University of Texas at Austin\",\n",
    "    \"University of Washington\",\n",
    "    \"University of Wisconsin-Madison\",\n",
    "    \"University of Illinois at Urbana-Champaign\",\n",
    "    \"Georgia Institute of Technology (Georgia Tech)\",\n",
    "    \"Pennsylvania State University\",\n",
    "    \"Rice University\",\n",
    "    \"University of California, Davis (UCD)\",\n",
    "    \"University of North Carolina, Chapel Hill\",\n",
    "    \"Boston University\",\n",
    "    \"Michigan State University\",\n",
    "    \"Texas A&M University\",\n",
    "    \"University of Maryland, College Park\",\n",
    "    \"Case Western Reserve University\",\n",
    "    \"University of Pittsburgh\",\n",
    "    \"University of Minnesota, Twin Cities\",\n",
    "    \"University of Florida\",\n",
    "    \"Vanderbilt University\",\n",
    "    \"Dartmouth College\",\n",
    "    \"Arizona State University\",\n",
    "    \"University of California, Irvine (UCI)\",\n",
    "    \"University of Notre Dame\",\n",
    "    \"Yeshiva University\",\n",
    "    \"University of Massachusetts, Amherst\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d76d8",
   "metadata": {},
   "source": [
    "# Popular Majors in the USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a37349",
   "metadata": {},
   "outputs": [],
   "source": [
    "majors = [\n",
    "    \"Business Administration\",\n",
    "    \"Accounting\",\n",
    "    \"Nursing\",\n",
    "    \"Psychology\",\n",
    "    \"Communications\",\n",
    "    \"Marketing\",\n",
    "    \"Education\",\n",
    "    \"Elementary Education\",\n",
    "    \"English\",\n",
    "    \"Computer Science\",\n",
    "    \"Finance\",\n",
    "    \"Criminal Justice\",\n",
    "    \"Biology\",\n",
    "    \"Political Science\",\n",
    "    \"Economics\",\n",
    "    \"Electrical Engineering\",\n",
    "    \"History\",\n",
    "    \"Liberal Arts\",\n",
    "    \"Sociology\",\n",
    "    \"Fine Arts\",\n",
    "    \"Commercial Art & Graphic Design\",\n",
    "    \"General Engineering\",\n",
    "    \"Journalism\",\n",
    "    \"Computer and Information Systems\",\n",
    "    \"Social Work\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec575d3",
   "metadata": {},
   "source": [
    "# Distributing Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "800610d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_university():\n",
    "    # For now, every university has the same chance of being selected\n",
    "    # Assuming 'universities' is your list\n",
    "    random_university = random.choice(universities)\n",
    "    \n",
    "    return random_university\n",
    "    \n",
    "def distribute_gender():\n",
    "    random_number = random.random()\n",
    "    \n",
    "    if random_number < 0.49:\n",
    "        return \"Female\"\n",
    "    else:\n",
    "        return \"Male\"\n",
    "    \n",
    "def distribute_ethnicity():\n",
    "    random_number = random.random()\n",
    "    \n",
    "    if random_number < 0.52:\n",
    "        return \"White\"\n",
    "    elif random_number < 0.55:\n",
    "        return \"American Indian or Alaska Native\"\n",
    "    elif random_number < 0.73:\n",
    "        return \"Black or African American\"\n",
    "    elif random_number < 0.8:\n",
    "        return \"Asian\"\n",
    "    else:\n",
    "        return \"Hispanic or Latino\"\n",
    "    \n",
    "def distribute_degree_level_and_age():\n",
    "    \"\"\"\n",
    "    Current distribution is not real, just assumed based on probable breakdown\n",
    "    \n",
    "    Then after that, pull a random age that they would like be in that program\n",
    "    \"\"\"\n",
    "    random_number = random.random()\n",
    "    \n",
    "    if random_number < 0.60:\n",
    "        return \"Bachelor's Degree\", random.randint(18, 22)\n",
    "    elif random_number < 0.94:\n",
    "        return \"Master's Degree\", random.randint(22, 30)\n",
    "    else:\n",
    "        return \"PHD\", random.randint(26, 35)\n",
    "    \n",
    "def distribute_major():\n",
    "    \"\"\"\n",
    "    Currently all majors have the same probability\n",
    "    \"\"\"\n",
    "    random_major = random.choice(majors)\n",
    "    \n",
    "    return random_major"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6ffc9b",
   "metadata": {},
   "source": [
    "# Generate Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd65f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name(eth, gend):\n",
    "    if gend == 'Male':\n",
    "        gen = 'Men'\n",
    "    else:\n",
    "        gen = 'Women'\n",
    "    f_names = first_names[f\"{eth} {gen}\"]\n",
    "    \n",
    "    first = f_names[random.randint(0,len(f_names)-1)].strip()\n",
    "    \n",
    "    l_names = last_names[f\"{eth}\"]\n",
    "    last = l_names[random.randint(0,len(l_names)-1)].strip()\n",
    "    \n",
    "    return f\"{first} {last}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99f3d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_persona():\n",
    "    p = {}\n",
    "    \n",
    "    # Distribute Ethnicity\n",
    "    eth = distribute_ethnicity()\n",
    "    # Distribute Gender\n",
    "    gend = distribute_gender()\n",
    "    \n",
    "    p['Name'] = generate_name(eth, gend)\n",
    "    \n",
    "    # Distribute Age and Income\n",
    "    degree, age = distribute_degree_level_and_age()\n",
    "    p['Age'] = str(age)\n",
    "    p['Ethnicity'] = eth\n",
    "    p['Gender'] = gend\n",
    "    \n",
    "    p['Degree'] = degree\n",
    "\n",
    "    # Distribute Education Level\n",
    "    p['Major'] = distribute_major()\n",
    "    \n",
    "    p['University'] = distribute_university()\n",
    "    \n",
    "    # Initialize a list of tuples that will be the question answers\n",
    "    p['QA'] = []\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8260bdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Jazlyn Phillips', 'Age': '29', 'Ethnicity': 'Black or African American', 'Gender': 'Female', 'Degree': \"Master's Degree\", 'Major': 'Accounting', 'University': 'University of Washington', 'QA': []}\n"
     ]
    }
   ],
   "source": [
    "poll_size = 10\n",
    "personas = []\n",
    "for i in range(poll_size):\n",
    "    personas.append(make_persona())\n",
    "print(personas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eb47c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persona_to_string(persona):\n",
    "\n",
    "    return (f\"Imagine you are {persona['Name']}, a {persona['Age']} year old {persona['Ethnicity']} {persona['Gender']} student at {persona['University']}. \"\n",
    "            f\"You are pursuing a {persona['Degree']} in {persona['Major']}. \"\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4036ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"How would your perfect professor provide constructive feedback on your assignments and projects?\",\n",
    "    \"What is your best thing a professor has done to aid in your learning during your college career?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc79a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_student(p, question):\n",
    "    \n",
    "    student_role = persona_to_string(p)\n",
    "    \n",
    "    first_name = p['Name'].split(\" \")[0]\n",
    "    \n",
    "    q_in = f\"{first_name}, could you please concisely answer the following question: {question}\"\n",
    "    \n",
    "    answer, usage = GPT.chat_gpt(q_in, engine='gpt-3.5-turbo-0613', temp=0.5, tokens = 600, role=student_role)\n",
    "    \n",
    "    return answer, usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49d268fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_student_questions(p, questions, num_follow_up=1, retries=3):  \n",
    "    global total_prompt_tokens, total_completion_tokens\n",
    "    try: \n",
    "        for question in questions:\n",
    "            # Ask the question to the persona\n",
    "            attempt = 0\n",
    "            while attempt <= retries:\n",
    "                try:   \n",
    "                    answer, usage = ask_student(p, question)\n",
    "\n",
    "                    # Add Usage to the totals for bookkeeping\n",
    "                    total_completion_tokens += usage['completion_tokens']\n",
    "                    total_prompt_tokens += usage['prompt_tokens']\n",
    "                    \n",
    "                    # Append the question answer to the personas list\n",
    "                    p['QA'].append((question, answer))\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    attempt += 1\n",
    "                    print(f\"Attempt {attempt} on date {day.date} - Error while generating themes: {e}\")\n",
    "                    if attempt > retries:\n",
    "                        print(\"Failed to generate themes after several attempts. Exiting.\")\n",
    "                        return None\n",
    "                    time.sleep(1)  # Wait for 1 second before retrying, this could be adjusted\n",
    "    except Exception as e:\n",
    "        # If any error occurs that has not been handled, return the exception\n",
    "        print(f\"Error on date: {day.date} with exception: {e}\")\n",
    "        return e\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Create and ask follow up questions\n",
    "        for i in range(num_follow_up):\n",
    "            # Ask the question to the persona\n",
    "            attempt = 0\n",
    "            while attempt <= retries:\n",
    "                try:   \n",
    "                    print(\"teststs\")\n",
    "                    question_gen_role = GPT.open_file(\"Prompts/follow_up_gen_role.txt\")\n",
    "                    \n",
    "                    question_gen_in = \"Please create a follow up question from the following:\\n\\n\"\n",
    "                    \n",
    "                    # Get the last 2 questions asked\n",
    "                    qa_len = len(p['QA'])\n",
    "                    q1 = p['QA'][qa_len-2]\n",
    "                    q2 = p['QA'][qa_len-1]\n",
    "                    \n",
    "                    # Add the first question\n",
    "                    question_gen_in += f\"Question: {q1[0]}\\n\"\n",
    "                    question_gen_in += f\"Answer: {q1[1]}\\n\\n\"\n",
    "                    \n",
    "                    # Add the second question\n",
    "                    question_gen_in += f\"Question: {q2[0]}\\n\"\n",
    "                    question_gen_in += f\"Answer: {q2[1]}\\n\\n\"\n",
    "                    \n",
    "                    new_q_text, usage = GPT.chat_gpt(question_gen_in, engine = 'gpt-3.5-turbo-0613' , role = question_gen_role, temp = 0.45, tokens = 1200)\n",
    "                    \n",
    "                    try:\n",
    "                        new_question = json.loads(new_q_text)['Question']\n",
    "                    except:\n",
    "                        print(\"the fuck\")\n",
    "                    \n",
    "                    new_answer, usage = ask_student(p, new_question)\n",
    "\n",
    "                    # Add Usage to the totals for bookkeeping\n",
    "                    total_completion_tokens += usage['completion_tokens']\n",
    "                    total_prompt_tokens += usage['prompt_tokens']\n",
    "                    \n",
    "                    # Append the question answer to the personas list\n",
    "                    p['QA'].append((new_question, new_answer))\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    attempt += 1\n",
    "                    print(f\"Attempt {attempt} on date {day.date} - Error while generating themes: {e}\")\n",
    "                    if attempt > retries:\n",
    "                        print(\"Failed to generate themes after several attempts. Exiting.\")\n",
    "                        return None\n",
    "                    time.sleep(1)  # Wait for 1 second before retrying, this could be adjusted\n",
    "        \n",
    "        print(\"Success\")\n",
    "        return \"Success\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        # If any error occurs that has not been handled, return the exception\n",
    "        print(f\"Error on date: {day.date} with exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44069043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teststs\n",
      "teststs\n",
      "teststs\n",
      "teststs\n",
      "teststs\n",
      "teststs\n",
      "teststs\n",
      "Success\n",
      "teststs\n",
      "Success\n",
      "the fuck\n",
      "Success\n",
      "teststs\n",
      "Success\n",
      "Success\n",
      "the fuck\n",
      "Success\n",
      "Success\n",
      "Error communicating with OpenAI: The server is overloaded or not ready yet.\n",
      "teststs\n",
      "Success\n",
      "Total Prompt Tokens: 2089\n",
      "Total Completion Tokens: 3011\n",
      "\n",
      "Token Cost = $ 0.010199999999999999\n"
     ]
    }
   ],
   "source": [
    "total_completion_tokens = 0\n",
    "total_prompt_tokens = 0\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # Submit tasks to the executor for each persona\n",
    "    futures = [executor.submit(ask_student_questions, persona, questions) for persona in personas]\n",
    "\n",
    "    # Wait for all tasks to complete\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "print(\"Total Prompt Tokens:\", total_prompt_tokens)\n",
    "print(\"Total Completion Tokens:\", total_completion_tokens)\n",
    "print()\n",
    "print(\"Token Cost = $\", str((total_prompt_tokens+total_completion_tokens)/1000*0.002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d103829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "\n",
      "3\n",
      "\n",
      "3\n",
      "\n",
      "3\n",
      "\n",
      "3\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for qa in personas:\n",
    "    print(len(qa['QA']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24132cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = \"unversitai_personas_with_QA.json\"\n",
    "\n",
    "# Open the file in write mode and save the dictionary as JSON\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(personas, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8014467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
